<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Soumil Goyal's Age Detection AI</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
</head>

<body>
    <video id="webcam" autoplay width="640px" height="480px"></video>
    <canvas id="canvas" width="640px" height="480px"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>

    <script>
        init();

        var video, canvas, context, URL, modelURL, metadataURL, facemodel, custommodel, faces, result;
        async function init() {
            video = document.getElementById("webcam");
            // video.width = "640px";
            // video.height = "480px";

            canvas = document.getElementById("canvas");
            context = canvas.getContext('2d');

            URL = "model/"
            modelURL = URL + "model.json";
            metadataURL = URL + "metadata.json";

            facemodel = await blazeface.load();
            custommodel = await tmImage.load(modelURL, metadataURL);

            navigator.mediaDevices.getUserMedia({
                    video: {
                        width: 600,
                        height: 400
                    },
                })
                .then(stream => {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        video.play();
                    };
                });

            classify();
        }






        async function facegiver() {
            const returnTensors = false;
            return await facemodel.estimateFaces(video, returnTensors);


        }

        async function classify() {
            faces = await facegiver();

            for (let i = 0; i < faces.length; i++) {
                const start = faces[i].topLeft;
                const end = faces[i].bottomRight;
                const size = [end[0] - start[0], end[1] - start[1]];

                // Render a rectangle over each detected face.
                context.beginPath();
                context.rect(start[0], start[1], size[0], size[1]);
                context.lineWidth = 2;
                context.strokeStyle = 'red';
                context.fillStyle = 'red';
                context.stroke();

                // Crop and resize the image to a square
                const face = context.getImageData(start[0], start[1], size[0], size[1]);
                const croppedFace = tf.image.resizeBilinear(face, [224, 224]);

                // Use your custom model for prediction
                // const prediction = await custommodel.predict(croppedFace);
                // context.fillText(prediction, start[0], start[1] > 10 ? start[1] - 5 : 10);
            }






            requestAnimationFrame(classify);
        }
    </script>
</body>

</html>